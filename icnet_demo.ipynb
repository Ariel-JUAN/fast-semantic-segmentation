{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICNet Demo for Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made to be a general reference showing how to do inference with one of the selected semantic segmentation models. It will assume you have downloaded a set of provided weights or have trained to create your own. \n",
    "\n",
    "## Converting the model checkpoint\n",
    "After having trained your model or downlaoded a set of weights, you should endup with a set of Tensorflow checkpoint files all sharing the extension `.ckpt`. Apart from your network stucture and parameters, these files also sotre training information and other data that might not be needed for deployment. Additionally, it is ideal to be able to store the final model in one single file.\n",
    "\n",
    "To do this, we first go through the process of \"freezing\" the model. Using the script `export.py`, follow the command line reference to freeze your model. Once this is finished, you should sned up with an output `.pb` file we can use in the next step of this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
